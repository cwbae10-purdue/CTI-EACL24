On Dec. 4, 2020, the Kubernetes Product Security Committee disclosed a new Kubernetes vulnerability assigned CVE-2020-8554.
It is a medium severity issue affecting all Kubernetes versions and is currently unpatched.
CVE-2020-8554 is a design flaw that allows Kubernetes Services to intercept cluster traffic to any IP address.
Users who can manage services can exploit the vulnerability to carry out man-in-the-middle (MITM) attacks against pods and nodes in the cluster.
Adversaries may utilize MITM attacks to masquerade as internal or external endpoints, harvest credentials from network traffic, tamper with a victim’s data before sending it to its intended target or block communications with specific IPs altogether.
Using encrypted protocols such as Transport Layer Security (TLS) can help, as attackers cannot easily access their traffic.
Multi-tenant clusters are most at risk, as they are most likely to have non-admin users that can manage services.
Attackers that compromised a single tenant may exploit the vulnerability to perform MITM attacks against other tenants in the cluster.
The Kubernetes Product Security Committee determined that patching CVE-2020-8554 would result in functionality changes to several Kubernetes features, so there is no plan to resolve the vulnerability in the short term.
Instead, the committee recommended several mitigations that restrict access to the vulnerable features, either based on a custom admission controller or through an Open Policy Agent (OPA) Gatekeeper rule.
Palo Alto Networks Prisma Cloud Compute customers can enable those mitigations through the built-in Admission support for OPA rules.
Please refer to the “Prisma Cloud Compute Mitigation” section for instructions.
CVE-2020-8554 stems from a design flaw in two features of Kubernetes Services: External IPs and Load Balancer IPs.
Kubernetes Services are an abstract way to expose an application running on a set of pods as a network service.
A service is exposed on one or more IPs.
Once deployed, nodes in the cluster will route traffic destined to the service IPs to one of the backing pods that make up the service.
When the cluster manages and assigns service IPs, all is well.
The problem starts when a Kubernetes user is able to assign arbitrary IPs to their services.
In that case, a malicious user can assign IPs that are already in use by other endpoints (internal or external), and intercept all cluster traffic to those IPs.
There are two methods to control the IP of a service:
Assign it an external IP.
Assign it a Load Balancer IP by patching the status.loadBalancer.ingress.ip field.
This method requires the patch service/status permission.
Below is a service that, when deployed to the cluster, will intercept all cluster DNS traffic to IP 8.8.8.8 (Google’s DNS Server) and route it to the evil-dns-server pod.
To receive the intercepted traffic, attackers must control the endpoints backing their malicious service.
In most cases, this will be a pod, like the evil-dns-server pod in the example above.
Services can also be backed by external endpoints (rather than cluster pods), which means attackers can also route intercepted traffic to an external endpoint outside of the cluster.
This requires the attacker to create a Kubernetes endpoint that points to an external address, which requires the create endpoint privilege.
The vulnerability affects all Kubernetes versions and is currently unpatched.
Clusters are affected if they meet these conditions:
Allow non-admin Kubernetes users to create or update services, or to patch the status of services; AND Allow those unprivileged users to control a pod (create, update or exec to pods); OR Allow those unprivileged users to create or update endpoints.
Allow those unprivileged users to control a pod (create, update or exec to pods); OR
Allow those unprivileged users to create or update endpoints.
Multi-tenant clusters are most at risk, as they are most likely to implement the vulnerable configuration above.
Multi-tenant clusters often segregate tenants using Kubernetes namespaces, limiting each tenant’s permissions to its namespace.
Unfortunately, even if a tenant can only manage service and pods in his own namespaces, it can still exploit CVE-2020-8554 to eavesdrop on traffic from the entire cluster.
Attackers that comprise a single tenant may exploit the vulnerability to intercept other tenants’ traffic and compromise them.
Clusters using Cilium to replace kube-proxy aren’t affected at all.
You may have been attacked if one of the following is true:
A service that shouldn’t expose external IPs or Load Balancer IPs does so.
An external IP or Load Balancer IP of a service matches an internal IP in the cluster – a pod IP or a clusterIP of another service.
An external IP or Load Balancer IP of a service points to a known external domain (e.g.
8.8.8.8).
Run nslookup <externalIP> to identify if an IP points to a known domain.
A Load Balancer IP of a service is 127.0.0.1 (indicates an attempt to hijack node localhost traffic).
To identify services in your cluster that expose external IPs, run the following command:
