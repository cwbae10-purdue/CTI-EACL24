In this hi-tech age, your face is increasingly becoming a digital ID for authenticating who you are online.
We look at how facial recognition works.
In this new age of wearable tech, biometrics and multi-factor authentication, your face is increasingly becoming your digital ID for authenticating who you are online.
But how does facial recognition software work and what are the caveats?
Not so new
Facial recognition technology is not exactly a new phenomenon, for all the recent headlines.
The first experimentations with the technology can be traced back to the 1960s, although, back then, the research going into its development was kept quiet.
Whereas today the science behind the software is much more mathematical, automatic and underpinned by sophisticated computer power, the early models required a greater level of human input and were therefore semi-automated.
It was also a relatively niche development.
No-one back then could quite have imagined that half a century later, facial recognition software would become so ubiquitous, both from a security point of view – used by the police, security professionals and the government – as well as a consumer benefit (for picking up people on a camera or as a means to password-protect a device).
Still evolving
While certainly commonplace, the technology behind facial recognition software is only just getting started – it has far from peaked.
For example, Microsoft is now using facial-recognition software for authentication in Windows 10, Apple is reportedly looking at ways for iOS users to automatically share photos with ‘tagged’ friends, while both Facebook and Google have been using facial recognition for users to tag friends and find pictures of themselves respectively.
Elsewhere, professors in China claim to have created the world’s first facial recognition ATM, while 30 churches around the world have been using the ‘Churchix’ software to find out who’s attending.
Meanwhile, researchers in Germany have been developing new facial recognition technology that can work in the dark, a sign perhaps of the future of face recognition and that Tom Cruise’s 2002 film Minority Report may not have been so outlandish after all.
The situation today
In recent years, facial recognition has predominantly been in operation at airports, on street corners and in other public areas.
Its use here has been relatively simple: a video camera collects images, which are then fed to a video surveillance system that is monitored by a manual worker.
This worker then pulls an image of a certain individual from the feed, and attempts to match it against the people already on their existing database.
Using a computer algorithm, the system attempts to identify someone by measuring certain features of their face, like the distance between their eyes or the width of their nose.
All that said, even to this day, this process is far from simple or straightforward.
A huge number of cameras still record pictures at a very low resolution, making identification almost impossible.
Further, the video surveillance systems themselves have little tolerance for changes in light, facial expressions or images captured at different angles.
From 2D to 3D
However, there are some positive developments.
In particular, the move from 2D to 3D image processing has helped improve identification.
The images are now able to collect a huge amount of additional information on a sub-milliter (or microwave) basis, and on everything from bone structure to curves around the eye socket, nose and chin.
This helps to build the face structure, and ultimately results in better, more accurate identification.
Crucially too, 3D modelling is less constrained by lighting or angles.
Images can easily be converted from 3D to 2D where required, and without losing any key data or identifiers.
In the event of face recognition not working, a number of vendors are now also working on skin biometrics to further aid with identification.
This sees a picture taken of a patch of skin, with the patch broken into smaller blocks so that it can be measured.
The system can then distinguish any lines, pores and the actual skin texture.
The software can reportedly identify differences between identical twins, which is not yet possible using facial recognition software alone, although there are also issues here on the use of eyeglasses and sunglasses, hair swept over the face, lighting and image resolution.
Challenges ahead
Facial recognition is, it seems, on an inevitable rise, but it does still face more than a few challenges.
The technical difficulties will likely dissipate as more vendors work on face recognition technology, although identification effectiveness is a big conundrum – the BBC recently reported that UK police were only able to identify one person from 4,000 images taken of the London riots in 2011.
There is now too the question of privacy, security and data transparency.
Wearable devices like Google Glass are seen as an invasion of privacy by some and there is a growing suspicion of what Google, Facebook, Twitter and others are collecting about their users.
A recent study from First Insight found that more than 75 per cent of US consumers would not shop at a store that use facial recognition technology for marketing purposes, and a similar study in the UK by RichRelevance found that most shoppers found in-store facial recognition to be “creepy”.
Security experts say that this highlights the need for greater transparency over what data is collected, and how it is stored and secured.
Additionally, initiatives like the Privacy Visor glasses, suggest that end-users could rebel against internet giants and their use of biometrics if this is not properly explained.
Others are also starting to look at from a legal point of view.
Jennifer Lynch, an attorney for privacy rights group Electronic Frontier Foundation, recently told Bloomberg: “Face recognition data can be collected without a person’s knowledge.
It’s very rare for a fingerprint to be collected without your knowledge.”
Whatever side of the fence you sit on, one thing is clear – the technology is here to stay.
