This is the third installment in a series on insider threats, industrial sabotage and game theory.
Be sure to read Part 1 for more information on the phases of an insider attack and Part 2 to learn about the concepts of collusion, cooperation and defection.
Before multiplayer games can be understood even in the simplest of terms, a refresher on two-player games is necessary — specifically the components of collusion, cooperation and defection, which form the basis for multiplayer games in game theory.
The second part of our series outlines this model.
We’ll leave the mathematics behind multiplayer games to Ph.D. candidates, but we can safely assume that the probability of colluding, cooperating and defecting becomes more complex as the number of players and possible outcomes for each game increase.
Before we continue to examine multiplayer games, it may be helpful to review the simple game theory model used in economics for a two-player game.
The model for a multiplayer game is best visualized using a matrix, similar to (but not exactly the same as) what mathematicians call matrix algebra:
The above model seems simple enough, so let’s apply it to Round 1 of the model game to get an idea of what this type of insider threat could look like:
Target Environment: Nuclear reactor control room at a fictitious energy provider — let’s call it Pluto Energy.
Primary Goal: Rattle the control rods in the reactor core and destroy them outright, potentially triggering a meltdown.
Players 1 and 2 are current employees of Pluto Energy.
Player 3 is a disgruntled former employee of Pluto Energy who has created a new worm capable of tunneling into in the antiquated software running in the nuclear reactor’s control room.
Result: The attempt was unsuccessful.
Secondary Goal: Trip the safety sensor and flood the reactor core.
Player 3 builds the worm, loads it onto a thumb drive and hands it to Player 1 on a designated day.
Player 1 inserts the thumb drive into the control room server during a shift change.
Players 1 and 2 ignore the control rod rattling and the safety alarm.
Result: The reactor core floods and the reactor is now inoperable.
Based on the result of the first round, if the target result was not achieved, the players would continue to the next round by finding a new attack technique, developing a new attack strategy or varying their entry points into the target environment.
So how does an environment protect itself against such a threat, and what can be done to solve these types of problems?
Practice game theory by establishing a skilled team of ethical hackers and certified penetration testers.
These individuals can be in-house employees or third-party experts, except for high-security environments, where outside consultants may not be allowed.
Environments that are serious about building a threat program and accompanying threats models should consider building red, blue and black teams, as well as practicing scenarios by participating in capture the flag games.
Typically, red teams focus on offensive capability while blue teams concentrate on defensive capability.
Black teams are involved in the complete scenario.
While not all environments face threats great enough to necessitate a black team, every organization should at least have red and a blue teams.
A handful of security firms employ ethical hackers, certified penetration testers and mathematical theorists to build the complex stochastic and probability models required to run simulated attack scenarios that produce usable results.
