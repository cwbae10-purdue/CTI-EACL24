On the afternoon of March 1st, an MSP partner reached out and warned our team about possible undisclosed Exchange vulnerabilities successfully exploiting on-prem servers.
We confirmed the activity and Microsoft has since released an initial blog and emergency patches for the vulnerabilities.
The purpose of this post is to spread the word that this is being actively exploited in the wild.
As of this post, we've discovered 100+ webshells across roughly 1,500 vulnerable servers  (AV/EDR installed) and expect this number to keep rising.
We'll continue to update this blog with our observations and IOCs to drive awareness.
Edit #1 3/3/2021: Based on the number of support tickets/questions we're getting from this post we've decided to host a webinar tomorrow where we'll go over our findings, what you should be doing, and give you a chance to ask our team questions.
Register now to join us Thursday, March 4th at 1:00pm EST.
Edit #2 3/4/2021: You can find the slides from the webinar here.
Edit #3 3/9/2021: Donâ€™t miss Tradecraft Tuesday today!
Weâ€™ll be taking a look at the tradecraft hackers used during the Microsoft Exchange Server exploit and share new post-exploitation details that you need to know about.
Update 16 - 03/12/2021 - 0458 ET
On Thursday afternoon (March 11th), security researcher Michael Gillespie reported ID Ransomware received a sudden increase in ransomware notices coming from IPs belonging to Microsoft Exchange servers.
The encrypted files can be identified by their .CRYPT file extension and the file marker DEARCRY!
(screenshot of the magic bytes).
The ransom notice is named readme.txt and includes the following contact emails:
Microsoft has since confirmed this new family of ransomware is being used after the initial compromise of unpatched on-premises Exchange Servers.
Microsoft Defender has received updates to detect this and may also be discoverable by the creation of a Service named msupdate according to James Quinn.___
Update 15 - 03/11/2021 - 1504 ET
We are observing an uptick in post-exploitation activity.
Many of these TTPs were previously disclosed in our March 9th Tradecraft Tuesday but the relevant slides can be found here:
Opera Browser DLL Sideloading Services
Cobalt Strike Loading from VSPerfMon Scheduled Tasks
Sapphire Pigeon Activity Leading to Mimikatz
PowerShell Based Lateral Movement Over SMB
With that said, there are some amazing blogs which highlight additional TTPs.
We strongly suggest reading these resources:
Elastic Blog Highlighting Collection of Network Recon Data
TrustedSec Blog with Awesome Post-Exploitation Details
ESET Diving into Multiple Reported Actors Exploiting This Situation
Update 14 - 03/11/2021 - 1413 ET
The last three days have been packed with mass analyzing verified intrusions of our partners.
With this data, we've shared specific threat actor IOCs (not client data) with relevant Law Enforcement, CERTs, and national security organizations.
For public organizations looking to do their own logging/monitoring/blocking/response, we feel comfortable sharing these observed exploit sources under TLP:WHITE.
Huntress has direct evidence these IP addresses were used for exploitation and webshell interaction:
Update 13 - 03/08/2021 - 1610 ET
If interested, tomorrow on Tradecraft Tuesday (March 9 at 1300 ET) we will be covering the post-exploitation techniques we have observed.
Everything from the web shells to the malware dropped.___
Update 12 - 03/06/2021 - 0632 ET
Yesterday we started seeing multiple partners' on-prem Exchange servers receive malicious scheduled tasks that executed a PowerShell downloader from hxxp://p.estonine[.]com/p?e.
This server was hosted on Digital Ocean and resolved to IP address 188.166.162[.
]201 and delivered a base64 encoded/compressed PowerShell script.
Oddly enough, this PowerShell looked very similar to a previous coin miner campaign reported by Carbon Black in 2019.
After reporting the incident to Digital Ocean (hosting) and NameCheap (registrar), we started digging into Layer 4 of the delivered payload.
After deobfucating this (which produced Layer 5) we learned there were two Mimikatz DLLs (x86 and x64) embedded within the script which gets reflectively loaded/injected.
Stay vigilant because it looks like things may start to heat up ðŸ”¥
Update 11 - 03/05/2021 - 2319 ET
Brian Krebs' fantastic reporting estimates 30,000+ unique US organizations have been compromised.
Many researchers beyond the Huntress team are scratching their heads on why did this incident escalated from the "limited and targeted" attacks observed by Volexity on Jan 6th, 2021 to this worldwide incident.
Notable commenters include former CISA Director Chris Krebs and Microsoft's Hafnium blog has been updated with additional resources to aid those performing investigations.
Also of note is Microsoft has updated their CSS Exchange repo on Github with their own Nmap NSE to "detect whether the specified URL is vulnerable to the Exchange Server SSRF Vulnerability (CVE-2021-26855)."
Folks have reported improved accuracy but warned a bug in Nmap could cause false inaccessibility errors.
This is reportedly fixable by adding --min-rtt-timeout 3 to Nmap's parameters.
We recommend using this Microsoft version going forward to assist validating your patch status and will provide feedback if we discover better alternatives.
Update 10 - 03/05/2021 - 1704 ET
Just a quick update to our 1254 ET post.
We've confirmed the Nmap NSE script will display "potentially vulnerable" for both fully patched server AND servers with only the most recent CU level (which is still vulnerable).
The script scrapes the OWA page to determine the version of Exchange.
The OWA page only includes the version number as major.minor.X but you need major.minor.X.Y to confirm the fully patched version.
That said, the script is useful for finding unpatched versions quickly.
Just be aware you need to verify the complete patch level for servers that have the most recent CU applied.
Also, the various Exchange registry keys, such as ClientAccessRole, are not completely reliable for patch verification.
Here only the latest CU level version is reported, but patches to a CU do not appear to update the version number stored in the registry.
Update 9 - 03/05/2021 - 1254 ET
Tons of folks couldn't join the webinar yesterday so we want to more useful points:
The internet is now mass scanning for these webshells
Microsoft published a script to assist the detection of malicious Exchange activity
The Nmap NSE to find vulnerable exchange boxes is not perfect (more on this shortly)
Using the registry's exchange build data is not perfect (more on this shortly)
More community resources are starting to pour in, so we'd like to highlight them:
NinjaRMM created great collection vendor knowledge.
Shodan has added some detection capabilities.
Unsure if it has the same accuracy issues as the Nmap NSE released earlier this week.
Update 8 - 03/04/2021 - 1628 ET
Just finished the webinar and our team is in the process of sending the slides and recordings.
In case you didn't make it, here's some of the most useful data
List of Huntress Discovered "China Chopper" ASPX Webshell Filenames - 04 March
PDF Version of the Presented Slides - 04 March
Microsoft Emergency Patches - 02 March
Had to split this into two posts (hit the Reddit limit).
See the older updates here.
I wrote some very fast (crappy) sripts to hunt for IOCs for this:
Tested on an IRL exchange 2016 server - detected recon from known bad IP on the 26/02/2021
Question related to this/the MS Hafnium Targeting Exchange article for the portion referencing
Select-String -Path "$env:PROGRAMFILES\Microsoft\Exchange Server\V15\Logging\ECP\Server\*.log" -Pattern 'Set-.+VirtualDirectory'
Your script indicates output should be entirely blank - as it should not output anything?
The article doesn't indicate specifics seemingly on what to look for if it outputs anything to help indicate what is normal/not normal.
It comments " All Set-<AppName>VirtualDirectory properties should never contain script.
InternalUrl and ExternalUrl should only be valid Uris. "
and of course comments this is a check for POTENTIAL compromise, but curious if anyone has additional information on this?
We have a few servers that output 'something' for this.
When I add a | Format-List to the end to read it, it truly doesn't become much more clear as to what did/didn't happen as far as malicious or not.
Running a Get-<AppName>VirtualDirectory on the instances that are named in the results, all appear still normal URLs.
The servers that I'm looking at had a mix of some having web shells/other items from the article and then others that this is the only item that really seems to generate anything.
Classic stance is likely that if nothing else is noticed it's *probably* fine but wondering if anyone knew more.
Really leads into the same question as others have regardless too, on what further action should be taken after IOCs identified anyway (assuming you have patched already).
Where did you see the IIS event ids reported as an IOC?
Those match entries in the System log for a compromise I can see, I just didn't see those reported anywhere.
Why is u/huntresslabs the only security vendor in here informing us of this issue.
What the hell are we paying for from everyone else?
Maybe it's because they care more about securing environments than just their bottom line numbers.
There's a reason all these other vendors are getting swallowed up by Ka**** and Th*** Br***, they ONLY care about the money.
Their priorities are out of whack.
It's not about securing your client environments, it's about how much money they can suck out of you for a false sense of security.
Huntress could've just informed their client base and moved on, but they came in here and put it on public display to help the community without expecting shit in return.
Thank you Huntress for being an amazing MSP security vendor!!
Apparently the only real security vendor in MSP land.
I have hung out with to Kyle and their team numerous times, their over reaching goal is to make security better and they don't just mean doing it by selling a product.
Security is a team sport and Huntress is a team player.
Some of the other companies just don't understand how security works in that context, but if their only goal is monetization then it's going to be hard for those companies to understand that concept.
Seriously, can't say enough good things about Kyle, Chris, John, and the entire team over at Huntress.
I do agree Huntress is phenomenal.
We use Automox for patching and they alerted us yesterday as well.
Do you mean the only one on Reddit doing it?
Several of mine have using other channels.
Not that Huntress doesn't rock, because they do.
Because half of the people in tech 2021 can write a mean Powershell script, spin up a AWS instance like the mean HR lady demands , and explain why Bitcoin kinda sorta works but 75% of us can't COMMUNICATE.
Sharing information in a centralized ITSM.
We gotta have 2-3 ticket systems we're always trying (failing) to integrate.
Too many cooks in the kitchen.
Why work on 2 projects with 5 qualified people when you can juggle 7 projects with 25 mostly qualified people across 4 time zones and 12 contractors can be hot swapped at the drop of a hat?
The way this industry has shifted is embarrassing and makes good staff want to quit entirely.
The security vendors you pay did not reach out to you directly?
You wait for them to post on reddit?
My SOCaaS reached out promptly yesterday.
Thanks for bringing this up.
I was investigating an incident from Sunday night that Crowdstrike stopped.
The SOC vendor was clueless, but the hair on the back of my neck stood up when we got the email from Huntress.
We had one file called 0cvxSJy9.aspx trying to harvest information.
Additionally, CS stopped the following from executing on the system.
"cmd" /c cd /d "C:\\inetpub\\wwwroot\\aspnet_client\\system_web"&net group "Exchange Organization administrators" administrator /del /domain&echo [S]&cd&echo [E]
It appears to be removing the administrator from the group.
Why would a threat actor do that without adding themselves in some way?
Also these "echo" commands obviously don't do much for them.
Your SOC vendor didn't understand the Crowdstrike alerts?
Does their service wrap include CS or was it something you brought along?
As for this command it was executed via a webshell with system level privileges.
I reckon it was in orders to make it harder for the box to recovered/remediated/patched by an Admin.
